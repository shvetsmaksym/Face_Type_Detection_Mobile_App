{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3b62d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "83c10b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Maksym Shvets\\\\Documents\\\\SFolder\\\\Face_Type_Detection_Mobile_App\\\\TrainingModels'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9bab41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lacking_px(image, target_size=(168, 224)):\n",
    "    \"\"\"Add missing pixels to the edges so the image is of target_size.\n",
    "    : param image: cv2 image\n",
    "    : param target_size: target width and hegth of output image\"\"\"\n",
    "    \n",
    "    temp_im = (np.array(image) / 255).astype(np.float32)\n",
    "    w, h = target_size\n",
    "\n",
    "    def solve_px_partition(ax_size, target):\n",
    "        if ax_size == target:\n",
    "            return (0, 0)\n",
    "        \n",
    "        resid = target - ax_size % target\n",
    "        \n",
    "        if resid % 2 == 0:\n",
    "            return resid // 2, resid // 2\n",
    "        else:\n",
    "            return resid // 2, resid // 2 + 1\n",
    "\n",
    "\n",
    "    # Define margins to add to the edges.\n",
    "    top, down = solve_px_partition(temp_im.shape[0], h)\n",
    "    left, right = solve_px_partition(temp_im.shape[1], w)\n",
    "\n",
    "    px_top = np.ones((top, temp_im.shape[1]))\n",
    "    px_down = np.ones((down, temp_im.shape[1]))\n",
    "    temp_im = np.vstack((px_top, temp_im, px_down))\n",
    "\n",
    "    px_left = np.ones((temp_im.shape[0], left))\n",
    "    px_right = np.ones((temp_im.shape[0], right))\n",
    "    temp_im = np.column_stack((px_left, temp_im, px_right))\n",
    "\n",
    "    \n",
    "    return temp_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fc25ed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c1e33760c44f95b042db86bfb05897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for class_dir in os.listdir(\"../Data/testing_set\")[:1]:\n",
    "    os.makedirs(f\"../Data/Processed/test/{class_dir}\", exist_ok=True)\n",
    "    \n",
    "    for file in tqdm_notebook(os.listdir(f\"../Data/testing_set/{class_dir}\")):\n",
    "        if not file.endswith(\".jpg\"):\n",
    "            continue\n",
    "            \n",
    "        img = cv2.imread(f\"../Data/testing_set/{class_dir}/{file}\")\n",
    "        try:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        while height > 224 or width > 168:\n",
    "            height, width = int(height * 0.5), int(width * 0.5)\n",
    "\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        # print(file, \"\\n\", img.shape)\n",
    "\n",
    "        # ADAPTIVE THRESHOLDING\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "        thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 3) \n",
    "\n",
    "        # ADD LACKING PIXELS TO THE EDGES\n",
    "        processed = add_lacking_px(thresh, target_size=(168, 224))\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.imshow(processed, 'gray')\n",
    "#         plt.show()\n",
    "#         print(\"processed image shape:\", processed.shape, \"\\n---------------------\")\n",
    "\n",
    "        cv2.imwrite(f\"../Data/Processed/test/{class_dir}/{file}\", processed * 255, [int(cv2.IMWRITE_PNG_COMPRESSION),0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a1d20d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014a094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
